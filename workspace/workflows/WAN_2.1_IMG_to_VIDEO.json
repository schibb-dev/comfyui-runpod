{
  "last_node_id": 11,
  "last_link_id": 10,
  "nodes": [
    {
      "id": 1,
      "type": "LoadImage",
      "pos": [100, 100],
      "size": {"0": 315, "1": 314},
      "flags": {},
      "order": 0,
      "mode": 0,
      "outputs": [
        {"name": "IMAGE", "type": "IMAGE", "links": [1], "slot_index": 0},
        {"name": "MASK", "type": "MASK", "links": null, "slot_index": 1}
      ],
      "properties": {"Node name for S&R": "LoadImage"},
      "widgets_values": ["example.png", "image"]
    },
    {
      "id": 2,
      "type": "CLIPTextEncode",
      "pos": [500, 100],
      "size": {"0": 400, "1": 200},
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [
        {"name": "clip", "type": "CLIP", "link": 2}
      ],
      "outputs": [
        {"name": "CONDITIONING", "type": "CONDITIONING", "links": [3], "slot_index": 0}
      ],
      "properties": {"Node name for S&R": "CLIPTextEncode"},
      "widgets_values": ["a beautiful landscape, cinematic, high quality"]
    },
    {
      "id": 3,
      "type": "CLIPTextEncode",
      "pos": [500, 350],
      "size": {"0": 400, "1": 200},
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [
        {"name": "clip", "type": "CLIP", "link": 2}
      ],
      "outputs": [
        {"name": "CONDITIONING", "type": "CONDITIONING", "links": [4], "slot_index": 0}
      ],
      "properties": {"Node name for S&R": "CLIPTextEncode"},
      "widgets_values": ["blurry, low quality, distorted"]
    },
    {
      "id": 4,
      "type": "UNETLoader",
      "pos": [100, 500],
      "size": {"0": 315, "1": 58},
      "flags": {},
      "order": 3,
      "mode": 0,
      "outputs": [
        {"name": "MODEL", "type": "MODEL", "links": [5], "slot_index": 0}
      ],
      "properties": {"Node name for S&R": "UNETLoader"},
      "widgets_values": ["diffusion_pytorch_model-00001-of-00007.safetensors"]
    },
    {
      "id": 5,
      "type": "CLIPLoader",
      "pos": [100, 600],
      "size": {"0": 315, "1": 58},
      "flags": {},
      "order": 4,
      "mode": 0,
      "outputs": [
        {"name": "CLIP", "type": "CLIP", "links": [2, 3], "slot_index": 0}
      ],
      "properties": {"Node name for S&R": "CLIPLoader"},
      "widgets_values": ["models_t5_umt5-xxl-enc-bf16.pth", "wan"]
    },
    {
      "id": 6,
      "type": "VAELoader",
      "pos": [100, 700],
      "size": {"0": 315, "1": 58},
      "flags": {},
      "order": 5,
      "mode": 0,
      "outputs": [
        {"name": "VAE", "type": "VAE", "links": [6], "slot_index": 0}
      ],
      "properties": {"Node name for S&R": "VAELoader"},
      "widgets_values": ["Wan2.1_VAE.pth"]
    },
    {
      "id": 7,
      "type": "VAEEncode",
      "pos": [500, 600],
      "size": {"0": 210, "1": 46},
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {"name": "pixels", "type": "IMAGE", "link": 1},
        {"name": "vae", "type": "VAE", "link": 6}
      ],
      "outputs": [
        {"name": "LATENT", "type": "LATENT", "links": [7], "slot_index": 0}
      ],
      "properties": {"Node name for S&R": "VAEEncode"}
    },
    {
      "id": 8,
      "type": "KSampler",
      "pos": [1000, 100],
      "size": {"0": 315, "1": 262},
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {"name": "model", "type": "MODEL", "link": 5},
        {"name": "positive", "type": "CONDITIONING", "link": 3},
        {"name": "negative", "type": "CONDITIONING", "link": 4},
        {"name": "latent_image", "type": "LATENT", "link": 7}
      ],
      "outputs": [
        {"name": "LATENT", "type": "LATENT", "links": [8], "slot_index": 0}
      ],
      "properties": {"Node name for S&R": "KSampler"},
      "widgets_values": [12345, 20, 6.0, "euler", "normal", 1.0]
    },
    {
      "id": 9,
      "type": "VAEDecode",
      "pos": [1400, 100],
      "size": {"0": 210, "1": 46},
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {"name": "samples", "type": "LATENT", "link": 8},
        {"name": "vae", "type": "VAE", "link": 6}
      ],
      "outputs": [
        {"name": "IMAGE", "type": "IMAGE", "links": [9], "slot_index": 0}
      ],
      "properties": {"Node name for S&R": "VAEDecode"}
    },
    {
      "id": 10,
      "type": "SaveImage",
      "pos": [1700, 100],
      "size": {"0": 315, "1": 270},
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {"name": "filename_prefix", "type": "STRING", "link": null},
        {"name": "images", "type": "IMAGE", "link": 9}
      ],
      "properties": {"Node name for S&R": "SaveImage"},
      "widgets_values": ["wan2.1_video"]
    },
    {
      "id": 11,
      "type": "Note",
      "pos": [100, 800],
      "size": {"0": 400, "1": 300},
      "flags": {},
      "order": 10,
      "mode": 0,
      "outputs": [],
      "properties": {},
      "widgets_values": [
               "WAN 2.1 IMG to VIDEO Workflow (Fixed Version)\n\n‚úÖ Uses correct loaders for WAN 2.1 models:\n‚Ä¢ UNETLoader: diffusion_pytorch_model-00001-of-00007.safetensors\n‚Ä¢ CLIPLoader: models_t5_umt5-xxl-enc-bf16.pth (type: wan)\n‚Ä¢ VAELoader: Wan2.1_VAE.pth\n\nüìÅ All models in correct directories:\n‚Ä¢ Diffusion models: ComfyUI/models/diffusion_models/\n‚Ä¢ Text encoders: ComfyUI/models/text_encoders/\n‚Ä¢ VAE models: ComfyUI/models/vae/\n\nüöÄ Ready to generate videos!\n\nUsage:\n1. Load an input image\n2. Set your positive and negative prompts\n3. Adjust sampling parameters\n4. Generate your video!\n\n‚úÖ Models are now accessible by ComfyUI loaders!"
      ]
    }
  ],
  "links": [
    [1, 1, 0, 7, 0, "IMAGE"],
    [2, 5, 0, 2, 0, "CLIP"],
    [3, 5, 0, 3, 0, "CLIP"],
    [4, 2, 0, 8, 1, "CONDITIONING"],
    [5, 3, 0, 8, 2, "CONDITIONING"],
    [6, 4, 0, 8, 0, "MODEL"],
    [7, 6, 0, 7, 1, "VAE"],
    [8, 7, 0, 8, 3, "LATENT"],
    [9, 8, 0, 9, 0, "LATENT"],
    [10, 9, 0, 10, 1, "IMAGE"]
  ],
  "groups": [],
  "config": {},
  "extra": {},
  "version": 0.4
}