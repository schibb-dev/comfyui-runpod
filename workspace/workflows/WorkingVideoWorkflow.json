{
  "1": {
    "class_type": "LoadImage",
    "inputs": {
      "image": "67036090c5a06665c942e137a2500ab6b091fa5f37ea1823ebd37d257289fe4e.jpeg"
    }
  },
  "2": {
    "class_type": "VAELoader",
    "inputs": {
      "vae_name": "wan_2.1_vae.safetensors"
    }
  },
  "3": {
    "class_type": "CLIPLoaderGGUFMultiGPU",
    "inputs": {
      "clip_name": "umt5-xxl-encoder-Q5_K_M.gguf",
      "type": "wan",
      "device": "cpu"
    }
  },
  "4": {
    "class_type": "CLIPTextEncode",
    "inputs": {
      "clip": [
        "3",
        0
      ],
      "text": "A girl in a white dress stands in a field of yellow flowers, holding a sword, under a sunlit forest. Slow and small Movements. Idle Animation"
    }
  },
  "5": {
    "class_type": "CLIPTextEncode",
    "inputs": {
      "clip": [
        "3",
        0
      ],
      "text": "\u8272\u8c03\u8273\u4e3d\uff0c\u8fc7\u66dd\uff0c\u9759\u6001\uff0c\u7ec6\u8282\u6a21\u7cca\u4e0d\u6e05\uff0c\u5b57\u5e55\uff0c\u98ce\u683c\uff0c\u4f5c\u54c1\uff0c\u753b\u4f5c\uff0c\u753b\u9762\uff0c\u9759\u6b62\uff0c\u6574\u4f53\u53d1\u7070\uff0c\u6700\u5dee\u8d28\u91cf\uff0c\u4f4e\u8d28\u91cf\uff0cJPEG\u538b\u7f29\u6b8b\u7559\uff0c\u4e11\u964b\u7684\uff0c\u6b8b\u7f3a\u7684\uff0c\u591a\u4f59\u7684\u624b\u6307\uff0c\u753b\u5f97\u4e0d\u597d\u7684\u624b\u90e8\uff0c\u753b\u5f97\u4e0d\u597d\u7684\u8138\u90e8\uff0c\u7578\u5f62\u7684\uff0c\u6bc1\u5bb9\u7684\uff0c\u5f62\u6001\u7578\u5f62\u7684\u80a2\u4f53\uff0c\u624b\u6307\u878d\u5408\uff0c\u9759\u6b62\u4e0d\u52a8\u7684\u753b\u9762\uff0c\u6742\u4e71\u7684\u80cc\u666f\uff0c\u4e09\u6761\u817f\uff0c\u80cc\u666f\u4eba\u5f88\u591a\uff0c\u5012\u7740\u8d70, fast movements, blurry, mouth moving, talking, teeth visible, strong blush, zoom out, zoom in"
    }
  },
  "6": {
    "class_type": "ImageResizeKJv2",
    "inputs": {
      "image": [
        "1",
        0
      ],
      "width": 512,
      "height": 768,
      "upscale_method": "nearest-exact",
      "keep_proportion": "crop",
      "pad_color": "0, 0, 0",
      "crop_position": "center",
      "divisible_by": 2,
      "device": "cpu"
    }
  },
  "7": {
    "class_type": "WanImageToVideo",
    "inputs": {
      "positive": [
        "4",
        0
      ],
      "negative": [
        "5",
        0
      ],
      "vae": [
        "2",
        0
      ],
      "start_image": [
        "6",
        0
      ],
      "width": 512,
      "height": 768,
      "length": 40,
      "batch_size": 1
    }
  },
  "8": {
    "class_type": "VAEDecode",
    "inputs": {
      "samples": [
        "7",
        2
      ],
      "vae": [
        "2",
        0
      ]
    }
  },
  "9": {
    "class_type": "VHS_VideoCombine",
    "inputs": {
      "images": [
        "8",
        0
      ],
      "frame_rate": 16,
      "loop_count": 0,
      "filename_prefix": "command_line_video",
      "format": "video/h264-mp4",
      "pingpong": false,
      "save_output": true
    }
  }
}